{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/qiskit/aqua/__init__.py:86: DeprecationWarning: The package qiskit.aqua is deprecated. It was moved/refactored to qiskit-terra For more information see <https://github.com/Qiskit/qiskit-aqua/blob/main/README.md#migration-guide>\n",
      "  warn_package('aqua', 'qiskit-terra')\n"
     ]
    }
   ],
   "source": [
    "from neuron import *\n",
    "from encodingsource import *\n",
    "from hsgs import *\n",
    "from classical_neuron import *\n",
    "from classical_pso import *\n",
    "from sf import *\n",
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from experiment_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding XOR Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[-1, -1],  [-1,1], [1,1], [1,-1]]\n",
    "y_train = [1, 0, 1, 0]\n",
    "\n",
    "X_test =  [[-1, -1],  [-1,1], [1,1], [1,-1]]\n",
    "y_test =  [1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = list(np.random.uniform(low=0.0, high=1.0, size=(len(X_test[0]),)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# GET ERROR BY EPOCH\n",
    "error_epoch_biased = experiment_TRAIN(X_train, \n",
    "                                       y_train,\n",
    "                                       lrParameter=0.1, \n",
    "                                       threshold=0.3,\n",
    "                                       n_epochs=100, \n",
    "                                       trainingBias=True,\n",
    "                                       trainingApproaches={'encoding-weight'})\n",
    "\n",
    "error_epoch_biased = pd.DataFrame({'epoch':list(range(0,100)), 'value':error_epoch_biased[1]})\n",
    "error_epoch_biased['model']='Encoding'\n",
    "error_epoch_biased.to_csv('testesout/outputs/XOR/error_by_epoch_bias_encoding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# GET ERROR BY EPOCH\n",
    "error_epoch_unbiased = experiment_TRAIN(X_train, \n",
    "                                       y_train,\n",
    "                                       lrParameter=0.1, \n",
    "                                       threshold=0.3,\n",
    "                                       n_epochs=100, \n",
    "                                       trainingBias=False,\n",
    "                                       trainingApproaches={'encoding-weight'})\n",
    "\n",
    "error_epoch_unbiased = pd.DataFrame({'epoch':list(range(0,100)), 'value':error_epoch_unbiased[1]})\n",
    "error_epoch_unbiased['model']='Encoding'\n",
    "error_epoch_unbiased.to_csv('testesout/outputs/XOR/error_by_epoch_nobias_encoding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'model':[],\n",
    "          #'phase_strategy':[],\n",
    "            'bias':[],\n",
    "            'threshold':[],\n",
    "            'lr':[],\n",
    "            'avg_error':[],\n",
    "            'trained_weights':[],\n",
    "            #'initial_weights':[],\n",
    "            'neuron_outputs':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "initial_weights =  list(np.random.uniform(low=0.0, high=1.0, size=(len(X_train[0]),)))\n",
    "threshold_space = [0.1, 0.3, 0.5, 0.7, 0.8]\n",
    "lr_space = [0.02, 0.1]\n",
    "bias_space = [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.75, 0.5, 0.5, 0.25, 0.25, 0.75, 0.5, 0.5, 0.25, 0.25, 0.25, 0.5, 0.5, 0.75, 0.5, 0.5, 0.25, 0.25, 0.5, 0.75, 0.75, 0.5, 0.25, 0.5, 0.75, 0.5, 0.5, 0.5, 0.5, 0.25] 0.475\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.75, 0.5, 0.5, 0.25, 0.75, 0.25, 0.25, 0.5, 0.75, 0.5, 0.25, 0.75, 0.5, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5] 0.4083333333333333\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] 0.5\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] 0.5\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] 0.5\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [0, 0, 0, 0]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 0.0\n",
      "\n",
      "\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "erros [1, 1, 1, 1] [1, 1, 1, 1]\n",
      "ERROS ENCODING     [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] 0.5\n",
      "\n",
      "\n",
      "CPU times: user 9min 14s, sys: 2.32 s, total: 9min 16s\n",
      "Wall time: 9min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for threshold in threshold_space:\n",
    "    for lr in lr_space:\n",
    "        for bias in bias_space:\n",
    "            # execute experiment\n",
    "            weights = experiment_TRAIN(X_train, \n",
    "                                       y_train,\n",
    "                                       lrParameter=lr, \n",
    "                                       threshold=threshold,\n",
    "                                       n_epochs=100, \n",
    "                                       trainingBias=bias,\n",
    "                                       trainingApproaches={'encoding-weight'})\n",
    "\n",
    "\n",
    "            results = experiment_TEST(X_test, \n",
    "                                      y_test, \n",
    "                                      threshold=threshold,\n",
    "                                      weightVectorsEncoding = weights[0], \n",
    "                                      repeat=10,\n",
    "                                      bias=bias,\n",
    "                                      testingApproaches={'encoding-weight'})\n",
    "\n",
    "\n",
    "            output['model'].append('Encoding')\n",
    "            output['lr'].append(lr)\n",
    "            output['bias'].append(bias)\n",
    "            output['threshold'].append(threshold)\n",
    "            output['avg_error'].append(results['error_encoding'])\n",
    "            output['neuron_outputs'].append(results['outputsEncoding'])\n",
    "            output['trained_weights'].append(results['weights_learned_encoding'])\n",
    "            #output['initial_weights'].append(initial_weights)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output).to_csv('testesout/outputs/XOR/encoding_XOR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
