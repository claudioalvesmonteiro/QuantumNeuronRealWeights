{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from neuron import *\n",
    "from encodingsource import *\n",
    "from hsgs import *\n",
    "from classical_neuron import *\n",
    "from classical_pso import *\n",
    "from sf import *\n",
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mantive esta célula para facilitar nossa busca pelo uso das funções HSGS, SF e Encoding.\n",
    "#### Criando neuronio usando hsgs, sf, encoding e comparando com o resultado clássico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding-input 0.0418701171875\n",
      "encoding-weight 0.2147216796875\n",
      "hsgs 0.2386474609375\n",
      "classico 0.21734167312340363\n"
     ]
    }
   ],
   "source": [
    "inputVector = [-1,-1,1,1]#[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]#[1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "weightVector = [1,1,-1,1] #[-1,1,-1,-1,1,1,1,1,1,1,1,1,1,1,1,1]#[1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1]\n",
    "\n",
    "inputVector = [-1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1]\n",
    "weightVector = [-0.03216409993230598, -0.1520999574184498, 0.11549307734856797, 0.07819667776917735, -0.08683451299393112, 0.07428209202455867, -0.011628350965060036, -0.058852035623669065, 0.02091024109530386, 0.18422984345689053, -0.12001327917718091, -0.17281808213991004, 0.004445115622186578, 0.09949334308845695, 0.0644906589346581, 0.17559849756856852, -0.088707282935652, -0.017908127406289862, -0.1026406028784107, 0.1885141061843412, 0.04853405915763267, -0.1894412214705037, -0.18971428207273894, -0.16080045829897144, -0.14494276618814597, 0.16133137423246743, 0.032410503109816365, 0.1554236889112614, -0.18999964114222914, -0.02773208631445002, -0.1769047447607832, 0.07340800548043382, 0.04977970093090443, -0.18319674721020804, -0.1611156274775103, -0.08041675891466839, -0.10661038807499998, -0.15819257805946796, -0.07129341872229379, 0.17219959076743557, -0.012891323765141861, 0.13884392920174257, -0.03493177735039414, -0.16967932466594843, -0.1344533324680956, 0.07710909951302578, 0.16230727329009179, -0.11811109546183819, 0.05762967585657125, 0.15720292553372192, -0.16562784891930163, -0.07348394951216673, -0.1298264325738957, -0.06989954242058431, 0.1662649564426879, 0.15549686702988463, -0.1345078290406552, 0.07132344671653838, 0.13820247035438069, -0.06455638157173038, 0.1549689794465881, -0.18061152100490427, 0.021178877641755214, -0.15711833018132063]\n",
    "\n",
    "operator = \"encoding-input\"\n",
    "neuron = createNeuron( inputVector, weightVector, operator)\n",
    "resultadoEncoding = executeNeuron(neuron, simulator, threshold=None)\n",
    "print(\"encoding-input\", resultadoEncoding)   \n",
    "operator = \"encoding-weight\"\n",
    "neuron = createNeuron( inputVector, weightVector, operator)\n",
    "resultadoEncoding = executeNeuron(neuron, simulator, threshold=None)\n",
    "print(\"encoding-weight\", resultadoEncoding)   \n",
    "operator = \"hsgs\"\n",
    "neuron = createNeuron(inputVector, weightVector, operator)\n",
    "resultadoHSGS = executeNeuron(neuron, simulator, threshold=None)\n",
    "print(\"hsgs\", resultadoHSGS)\n",
    "\n",
    "resultadoClassico = runClassicalNeuronReturnProbability(inputVector, weightVector)\n",
    "print(\"classico\", resultadoClassico)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando Base simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base com X, Quadrado e Círculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1], [1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1], [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1]]\n",
      "[0, 1, 2]\n",
      "[[-1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1], [-1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1], [-1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1], [-1, 1, 1, -1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1], [-1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1], [-1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1], [1, 1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1], [-1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1], [-1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1], [1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1], [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1], [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1], [1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1], [1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1], [1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1], [-1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1], [1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1], [1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1], [-1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1], [-1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1], [-1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1], [-1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, 1, -1]]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X1 = [-1,  1,  1, -1,\n",
    "       1, -1, -1,  1,\n",
    "       1, -1, -1,  1,\n",
    "      -1,  1,  1, -1]\n",
    "\n",
    "CRUZ1 = [ 1, -1, -1,  1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1,  1]\n",
    "\n",
    "Q1 = [-1, -1, -1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "\n",
    "C1 = [ 1, -1, -1,  1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "\n",
    "X2 = [-1,  1, -1, -1,\n",
    "       1, -1, -1,  1,\n",
    "       1, -1, -1,  1,\n",
    "      -1,  1,  1, -1]\n",
    "X3 = [-1,  1,  1, -1,\n",
    "       1, -1, -1,  1,\n",
    "       1, -1, -1, -1,\n",
    "      -1,  1,  1, -1]\n",
    "X4 = [-1,  1,  1, -1,\n",
    "       1, 1, -1,  1,\n",
    "       1, -1, -1,  1,\n",
    "      -1,  1,  1, -1]\n",
    "X5 = [-1,  1,  1, -1,\n",
    "       1, -1, 1,  1,\n",
    "       1, -1, -1,  1,\n",
    "      -1,  1,  1, -1]\n",
    "X6 = [-1,  1,  1, -1,\n",
    "       1, -1, -1,  1,\n",
    "       1, -1, -1, -1,\n",
    "      -1,  1,  1, -1]\n",
    "X7 = [-1,  1,  1, -1,\n",
    "       1, -1, -1,  1,\n",
    "       1,  1, -1,  1,\n",
    "      -1,  1,  1, -1]\n",
    "X8 = [ 1,  1,  1, -1,\n",
    "       1, -1, -1,  1,\n",
    "       1, -1, -1,  1,\n",
    "      -1,  1,  1, -1]\n",
    "X9 = [-1,  1,  1,  1,\n",
    "       1, -1, -1,  1,\n",
    "       1, -1, -1,  1,\n",
    "       1,  1,  1, -1]\n",
    "X10 = [-1,  1,  1, -1,\n",
    "       1, -1, -1,  1,\n",
    "       1,  1,  1,  1,\n",
    "      -1,  1,  1, -1]\n",
    "\n",
    "CRUZ2 = [ 1, -1, -1,  1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1,  1]\n",
    "\n",
    "CRUZ3 = [-1, -1, -1,  1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1,  1]\n",
    "CRUZ4 = [ 1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1,  1]\n",
    "CRUZ5 = [ 1, -1, -1,  1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1, -1]\n",
    "CRUZ6 = [ 1, -1, -1,  1,\n",
    "         -1,  1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1,  1]\n",
    "CRUZ7 = [ 1, -1,  1,  1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1,  1]\n",
    "CRUZ8 = [-1, -1,  1,  1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1, -1, -1,  1]\n",
    "CRUZ9 = [ 1, -1, -1,  1,\n",
    "         -1, -1, -1, -1,\n",
    "         -1, -1, -1, -1,\n",
    "          1,  1, -1,  1]\n",
    "CRUZ10 = [ 1, -1, -1,  1,\n",
    "          -1, -1, -1, -1,\n",
    "          -1, -1,  1, -1,\n",
    "           1, -1,  1,  1]\n",
    "\n",
    "Q2 = [-1, -1, -1, -1,\n",
    "      -1, -1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "Q3 = [-1, -1, -1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "\n",
    "Q4 = [-1, -1, -1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1, -1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "\n",
    "Q5 = [-1, -1, -1, -1,\n",
    "      -1,  1, -1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "Q6 = [-1, -1, -1, -1,\n",
    "      -1, -1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "Q7 = [-1, -1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "Q8 = [-1, -1, -1, -1,\n",
    "       1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "Q9 = [-1, -1, -1, 1,\n",
    "      -1,  1,  1, 1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, -1, -1]\n",
    "Q10 = [-1, -1, 1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1, -1, 1, -1]\n",
    "\n",
    "C2 = [ 1, -1, -1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "C3 = [ 1,  1, -1,  1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "C4 = [ 1, -1, -1,  1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1, -1,  1,  1]\n",
    "C5 = [ 1, -1, -1,  1,\n",
    "       1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "C6 = [ 1, -1, -1,  1,\n",
    "      -1,  1,  1, -1,\n",
    "       1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "C7 = [ 1, -1, -1,  1,\n",
    "      -1,  1, -1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "C8 = [ 1, -1, -1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "C9 = [ 1, -1,  1,  1,\n",
    "      -1,  1,  1, -1,\n",
    "      -1,  1,  1, -1,\n",
    "       1,  1, -1,  1]\n",
    "C10 = [ 1, -1, -1,  1,\n",
    "      -1,  1,  1,  1,\n",
    "       1,  1,  1, -1,\n",
    "       1, -1, -1,  1]\n",
    "\n",
    "\n",
    "#X = [[-1,-1,-1,-1], [1,-1,-1,-1],[1,1,1,-1], [1,1,-1,-1]]\n",
    "#y = [0,0,1,1]\n",
    "\n",
    "#Xs_train, Xs_test, ys_train, ys_test = train_test_split(X, y, test_size=0.5, stratify=y,  random_state = 123)\n",
    "\n",
    "Xs_train = [X1, CRUZ1, Q1]\n",
    "ys_train = [0, 1, 2]\n",
    "\n",
    "Xs_test = [X2, X3, X4, X5, X6, X7, X8, X9, X10, CRUZ2, CRUZ3, CRUZ4, CRUZ5, CRUZ6,CRUZ7,CRUZ8,CRUZ9,CRUZ10, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q10]\n",
    "ys_test = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "print(Xs_train)\n",
    "print(ys_train)\n",
    "print(Xs_test)\n",
    "print(ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de aprendizado 0.2\n",
      "erro HSGS 2.8106689453125 erro encoding 2.8565673828125 melhores erros 2.8106689453125 2.8565673828125\n",
      "erro HSGS 2.8118896484375 erro encoding 2.72607421875 melhores erros 2.8106689453125 2.72607421875\n",
      "erro HSGS 2.8140869140625 erro encoding 2.4815673828125 melhores erros 2.8106689453125 2.4815673828125\n",
      "erro HSGS 2.81005859375 erro encoding 2.236083984375 melhores erros 2.81005859375 2.236083984375\n",
      "erro HSGS 2.8165283203125 erro encoding 1.9288330078125 melhores erros 2.81005859375 1.9288330078125\n",
      "erro HSGS 2.8145751953125 erro encoding 1.7125244140625 melhores erros 2.81005859375 1.7125244140625\n",
      "erro HSGS 0.0 erro encoding 1.527587890625 melhores erros 0.0 1.527587890625\n",
      "erro HSGS 0.0 erro encoding 1.3797607421875 melhores erros 0.0 1.3797607421875\n",
      "erro HSGS 0.0 erro encoding 1.2457275390625 melhores erros 0.0 1.2457275390625\n",
      "erro HSGS 0.0 erro encoding 1.1507568359375 melhores erros 0.0 1.1507568359375\n",
      "erro HSGS 0.0 erro encoding 1.048828125 melhores erros 0.0 1.048828125\n",
      "erro HSGS 0.0 erro encoding 0.972900390625 melhores erros 0.0 0.972900390625\n",
      "erro HSGS 0.0 erro encoding 0.929443359375 melhores erros 0.0 0.929443359375\n",
      "erro HSGS 0.0 erro encoding 0.87841796875 melhores erros 0.0 0.87841796875\n",
      "erro HSGS 0.0 erro encoding 0.8250732421875 melhores erros 0.0 0.8250732421875\n",
      "erro HSGS 0.0 erro encoding 0.788330078125 melhores erros 0.0 0.788330078125\n",
      "erro HSGS 0.0 erro encoding 0.7452392578125 melhores erros 0.0 0.7452392578125\n",
      "erro HSGS 0.0 erro encoding 0.7147216796875 melhores erros 0.0 0.7147216796875\n",
      "erro HSGS 0.0 erro encoding 0.6932373046875 melhores erros 0.0 0.6932373046875\n",
      "erro HSGS 0.0 erro encoding 0.6639404296875 melhores erros 0.0 0.6639404296875\n",
      "erro HSGS 0.0 erro encoding 0.6378173828125 melhores erros 0.0 0.6378173828125\n",
      "erro HSGS 0.0 erro encoding 0.6201171875 melhores erros 0.0 0.6201171875\n",
      "erro HSGS 0.0 erro encoding 0.5919189453125 melhores erros 0.0 0.5919189453125\n",
      "erro HSGS 0.0 erro encoding 0.5689697265625 melhores erros 0.0 0.5689697265625\n",
      "erro HSGS 0.0 erro encoding 0.5628662109375 melhores erros 0.0 0.5628662109375\n",
      "erro HSGS 0.0 erro encoding 0.5447998046875 melhores erros 0.0 0.5447998046875\n",
      "erro HSGS 0.0 erro encoding 0.5250244140625 melhores erros 0.0 0.5250244140625\n",
      "erro HSGS 0.0 erro encoding 0.5234375 melhores erros 0.0 0.5234375\n",
      "erro HSGS 0.0 erro encoding 0.5023193359375 melhores erros 0.0 0.5023193359375\n",
      "erro HSGS 0.0 erro encoding 0.49658203125 melhores erros 0.0 0.49658203125\n",
      "erro HSGS 0.0 erro encoding 0.4715576171875 melhores erros 0.0 0.4715576171875\n",
      "erro HSGS 0.0 erro encoding 0.4681396484375 melhores erros 0.0 0.4681396484375\n",
      "erro HSGS 0.0 erro encoding 0.45751953125 melhores erros 0.0 0.45751953125\n",
      "erro HSGS 0.0 erro encoding 0.4542236328125 melhores erros 0.0 0.4542236328125\n",
      "erro HSGS 0.0 erro encoding 0.44775390625 melhores erros 0.0 0.44775390625\n",
      "erro HSGS 0.0 erro encoding 0.4229736328125 melhores erros 0.0 0.4229736328125\n",
      "erro HSGS 0.0 erro encoding 0.42529296875 melhores erros 0.0 0.4229736328125\n",
      "erro HSGS 0.0 erro encoding 0.408447265625 melhores erros 0.0 0.408447265625\n",
      "erro HSGS 0.0 erro encoding 0.3873291015625 melhores erros 0.0 0.3873291015625\n",
      "erro HSGS 0.0 erro encoding 0.3824462890625 melhores erros 0.0 0.3824462890625\n",
      "erro HSGS 0.0 erro encoding 0.3841552734375 melhores erros 0.0 0.3824462890625\n",
      "erro HSGS 0.0 erro encoding 0.3782958984375 melhores erros 0.0 0.3782958984375\n",
      "erro HSGS 0.0 erro encoding 0.372314453125 melhores erros 0.0 0.372314453125\n",
      "erro HSGS 0.0 erro encoding 0.3619384765625 melhores erros 0.0 0.3619384765625\n",
      "erro HSGS 0.0 erro encoding 0.3603515625 melhores erros 0.0 0.3603515625\n",
      "erro HSGS 0.0 erro encoding 0.350830078125 melhores erros 0.0 0.350830078125\n",
      "erro HSGS 0.0 erro encoding 0.3433837890625 melhores erros 0.0 0.3433837890625\n",
      "erro HSGS 0.0 erro encoding 0.3507080078125 melhores erros 0.0 0.3433837890625\n",
      "erro HSGS 0.0 erro encoding 0.335205078125 melhores erros 0.0 0.335205078125\n",
      "erro HSGS 0.0 erro encoding 0.329833984375 melhores erros 0.0 0.329833984375\n"
     ]
    }
   ],
   "source": [
    "thresholdParameter = 0.5 #nao é usado\n",
    "\n",
    "def treinamentoNeuronio(operator,inputVector, weightVector, y_train):\n",
    "    if (operator == \"hsgs\"):\n",
    "        wBinaryBinary = deterministicBinarization(weightVector) # Binarization of Real weights\n",
    "        neuron = createNeuron(inputVector, wBinaryBinary, operator)\n",
    "        resultado = executeNeuron(neuron, simulator, threshold=None)\n",
    "        deltaRule(inputVector, weightVector, threshold=thresholdParameter, lr=lrParameter, y_train=y_train, out=resultado)\n",
    "        return resultado\n",
    "    elif (operator == \"encoding-weight\"):\n",
    "        #wBinaryBinary = deterministicBinarization(weightVector) # Binarization of Real weights\n",
    "        neuron = createNeuron(inputVector, weightVector, operator)\n",
    "        resultado = executeNeuron(neuron, simulator, threshold=None)\n",
    "        deltaRule(inputVector, weightVector, threshold=thresholdParameter, lr=lrParameter, y_train=y_train, out=resultado)\n",
    "        return resultado\n",
    "        \n",
    "nClasses = 3\n",
    "weightVectorsHSGS = []#[[-1, -1, -1, -1], [1, 1, 1, -1]]#[[-1, -1, -1, -1], [-1, -1, -1, -1]]#[[1,1,1,1]]*nClasses\n",
    "weightVectorsEncoding = []#[[-1, -1, -1, -1], [1, 1, 1, -1]]#[[-1, -1, -1, -1], [-1, -1, -1, -1]]#[[1,1,1,1]]*nClasses\n",
    "\n",
    "input_dim = 2**4\n",
    "\n",
    "for i in range(nClasses):\n",
    "    weightVectorsHSGS.append(deterministicBinarization(np.random.uniform(-1, 1, input_dim)))\n",
    "    weightVectorsEncoding.append(deterministicBinarization(np.random.uniform(-1, 1, input_dim)))\n",
    "\n",
    "\n",
    "bestWeightsHSGS = []\n",
    "bestWeightsEncoding = []\n",
    "bestErrorHSGS=999999\n",
    "bestErrorEncoding = 999999\n",
    "\n",
    "limiarErroToleravel = 0.03\n",
    "n_epochs = 300\n",
    "\n",
    "for lrParameter in [0.2]:\n",
    "    print(\"taxa de aprendizado\",lrParameter )\n",
    "    tamTreinamento = len(Xs_train)\n",
    "\n",
    "    for iteration in range(n_epochs):\n",
    "        erroHSGS = 0\n",
    "        erroEncoding = 0\n",
    "\n",
    "        errosHSGS=[]\n",
    "        errosEncoding = []\n",
    "        for posicaoTreinamento in range(tamTreinamento):\n",
    "            \n",
    "            inputVector = Xs_train[posicaoTreinamento] # inputVectors[posicaoTreinamento]\n",
    "            y_train = ys_train[posicaoTreinamento]\n",
    "\n",
    "            #print(inputVector, y_train)\n",
    "\n",
    "            \"\"\"\n",
    "            executando o HSGS\n",
    "            \"\"\"\n",
    "            operator = \"hsgs\"\n",
    "            resultadoHSGS = treinamentoNeuronio(operator,inputVector, weightVectorsHSGS[y_train], y_train=1)\n",
    "            \"\"\"\n",
    "            executando o encoding\n",
    "            \"\"\"\n",
    "            operator = \"encoding-weight\"\n",
    "            resultadoEncoding = treinamentoNeuronio(operator,inputVector, weightVectorsEncoding[y_train], y_train=1)\n",
    "\n",
    "            #print(\"PESOS ENCODING\",weightVectorsEncoding)\n",
    "\n",
    "\n",
    "            #print(\"resultadoHSGS\", resultadoHSGS)\n",
    "            #print(\"encoding\", resultadoEncoding)\n",
    "            \"\"\"\n",
    "            erros\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            #old\n",
    "            resultadoEncoding_bin = 0\n",
    "            if abs(resultadoEncoding) > threshold:\n",
    "                resultadoEncoding_bin = 1\n",
    "\n",
    "            resultadoHSGS_bin = 0\n",
    "            if abs(resultadoHSGS) > threshold:\n",
    "                resultadoHSGS_bin = 1\n",
    "\n",
    "\n",
    "            erroHSGS += abs(resultadoHSGS_bin)####abs(resultadoHSGS_bin-y_train)\n",
    "            erroEncoding += abs(resultadoEncoding_bin)####abs(resultadoEncoding_bin-y_train)\n",
    "            \"\"\"\n",
    "            errosHSGS.append(1-resultadoHSGS)\n",
    "            errosEncoding.append(1-resultadoEncoding)\n",
    "\n",
    "            erroHSGS += abs(1-resultadoHSGS)####abs(resultadoHSGS_bin-y_train)\n",
    "            erroEncoding += abs(1-resultadoEncoding)####abs(resultadoEncoding_bin-y_train)\n",
    "            \n",
    "            \n",
    "        if (erroHSGS < bestErrorHSGS):\n",
    "            bestWeightsHSGS = weightVectorsHSGS[:]\n",
    "            bestErrorHSGS = erroHSGS\n",
    "        \n",
    "        if (erroEncoding < bestErrorEncoding):\n",
    "            bestWeightsEncoding = weightVectorsEncoding[:]\n",
    "            bestErrorEncoding = erroEncoding\n",
    "            \n",
    "        print(\"erro HSGS\", erroHSGS, \"erro encoding\", erroEncoding, \"melhores erros\", bestErrorHSGS, bestErrorEncoding)\n",
    "\n",
    "\n",
    "        #print(\"erros\", errosHSGS, errosEncoding)\n",
    "        #if erroEncoding < limiarErroToleravel or erroHSGS < limiarErroToleravel:\n",
    "        #        break\n",
    "    print(\"erros\", errosHSGS, errosEncoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weightVectorsEncoding = bestWeightsEncoding\n",
    "weightVectorsHSGS = bestWeightsHSGS\n",
    "\n",
    "print(\"PESOS HSGS\", weightVectorsHSGS)\n",
    "print()\n",
    "print(\"PESOS Encoding\", weightVectorsEncoding)\n",
    "print()\n",
    "\n",
    "errosHSGS = []\n",
    "errosEncoding = []\n",
    "for i in range(30):\n",
    "    erroHSGS = 0\n",
    "    erroEncoding = 0\n",
    "\n",
    "    for posicaoTreinamento in range(len(Xs_test)):\n",
    "        inputVector = Xs_test[posicaoTreinamento] # inputVectors[posicaoTreinamento]\n",
    "        y_train = ys_test[posicaoTreinamento]\n",
    "\n",
    "        valorMaiorHSGS=0\n",
    "        neuronMaiorHSGS=0\n",
    "\n",
    "        valorMaiorEncoding=0\n",
    "        neuronMaiorEncoding=0\n",
    "\n",
    "        for neuronClass in range(nClasses):\n",
    "            operator = \"hsgs\"\n",
    "            wBinaryBinary = deterministicBinarization(weightVectorsHSGS[neuronClass]) # Binarization of Real weights\n",
    "            neuron = createNeuron(inputVector, wBinaryBinary, operator)\n",
    "            resultadoHSGS1 = executeNeuron(neuron, simulator, threshold=None)\n",
    "\n",
    "            if(resultadoHSGS1>valorMaiorHSGS):\n",
    "                neuronMaiorHSGS = neuronClass\n",
    "                valorMaiorHSGS = resultadoHSGS1\n",
    "\n",
    "            operator = \"encoding-weight\"\n",
    "            #wBinaryBinary = deterministicBinarization(weightVectorsEncoding[neuronClass]) # Binarization of Real weights\n",
    "            neuron = createNeuron(inputVector, weightVectorsEncoding[neuronClass], operator)\n",
    "            resultadoEncoding1 = executeNeuron(neuron, simulator, threshold=None)\n",
    "\n",
    "            if(resultadoEncoding1 > valorMaiorEncoding):\n",
    "                neuronMaiorEncoding = neuronClass\n",
    "                valorMaiorEncoding = resultadoEncoding1\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        erros\n",
    "        \"\"\"\n",
    "        erroHSGS_bin = 0\n",
    "        if (neuronMaiorHSGS != y_train):   \n",
    "            erroHSGS_bin = 1\n",
    "\n",
    "        erroEncoding_bin = 0\n",
    "        if (neuronMaiorEncoding != y_train):   \n",
    "            erroEncoding_bin = 1\n",
    "        \n",
    "        print(\"classe\", y_train, \"HSGS\", neuronMaiorHSGS ,\"ENCODING\", neuronMaiorEncoding)\n",
    "\n",
    "\n",
    "        #print(\"\\nerro Encoding:\", abs(resultadoEncoding_bin-y_train))\n",
    "        #print(\"erro HSGS:\", abs(resultadoHSGS_bin-y_train))\n",
    "        erroHSGS += erroHSGS_bin####abs(resultadoHSGS_bin-y_train)\n",
    "        erroEncoding += erroEncoding_bin####abs(resultadoEncoding_bin-y_train)\n",
    "    print()\n",
    "    print(\"erro HSGS\", erroHSGS, \"erro encoding\", erroEncoding)\n",
    "    errosHSGS.append(erroHSGS)\n",
    "    errosEncoding.append(erroEncoding)\n",
    "\n",
    "print(\"ERROS HSGS\", errosHSGS, np.average(errosHSGS))\n",
    "print(\"ERROS ENCODING\", errosEncoding, np.average(errosEncoding))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxasHSGS = errosHSGS#[7, 9, 9, 9, 9, 7, 10, 10, 8, 11, 11, 5, 9, 9, 5, 5, 13, 6, 6, 9, 7, 11, 8, 10, 11, 13, 12, 9, 8, 11]\n",
    "taxasHSGSPerc = []\n",
    "mediaHSGS = 0\n",
    "for t in taxasHSGS:\n",
    "    mediaHSGS += t/27\n",
    "    taxasHSGSPerc.append(round(t/27,3))\n",
    "print(taxasHSGSPerc)\n",
    "print(round(np.average(taxasHSGSPerc),3), round(np.std(taxasHSGSPerc),6))\n",
    "\n",
    "taxasEncoding = errosEncoding#[6, 6, 6, 7, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5]\n",
    "taxasEncodingPerc = []\n",
    "mediaEncoding = 0\n",
    "for t in taxasEncoding:\n",
    "    mediaEncoding += t/27\n",
    "    taxasEncodingPerc.append(round(t/27,3))\n",
    "print(taxasEncodingPerc)\n",
    "print(round(np.average(taxasEncodingPerc),3), round(np.std(taxasEncodingPerc),6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colocando os pesos encontrados pelo treinamento no Encoding e no HSGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weightVectorsEncoding = bestWeightsEncoding\n",
    "weightVectorsHSGS = bestWeightsEncoding# bestWeightsHSGS\n",
    "\n",
    "print(\"PESOS HSGS\", weightVectorsHSGS)\n",
    "print()\n",
    "print(\"PESOS Encoding\", weightVectorsEncoding)\n",
    "print()\n",
    "\n",
    "errosHSGS = []\n",
    "errosEncoding = []\n",
    "for i in range(30):\n",
    "    erroHSGS = 0\n",
    "    erroEncoding = 0\n",
    "\n",
    "    for posicaoTreinamento in range(len(Xs_test)):\n",
    "        inputVector = Xs_test[posicaoTreinamento] # inputVectors[posicaoTreinamento]\n",
    "        y_train = ys_test[posicaoTreinamento]\n",
    "\n",
    "        valorMaiorHSGS=0\n",
    "        neuronMaiorHSGS=0\n",
    "\n",
    "        valorMaiorEncoding=0\n",
    "        neuronMaiorEncoding=0\n",
    "\n",
    "        for neuronClass in range(nClasses):\n",
    "            operator = \"hsgs\"\n",
    "            wBinaryBinary = deterministicBinarization(weightVectorsHSGS[neuronClass]) # Binarization of Real weights\n",
    "            neuron = createNeuron(inputVector, wBinaryBinary, operator)\n",
    "            resultadoHSGS1 = executeNeuron(neuron, simulator, threshold=None)\n",
    "\n",
    "            if(resultadoHSGS1>valorMaiorHSGS):\n",
    "                neuronMaiorHSGS = neuronClass\n",
    "                valorMaiorHSGS = resultadoHSGS1\n",
    "\n",
    "            operator = \"encoding-weight\"\n",
    "            #wBinaryBinary = deterministicBinarization(weightVectorsEncoding[neuronClass]) # Binarization of Real weights\n",
    "            neuron = createNeuron(inputVector, weightVectorsEncoding[neuronClass], operator)\n",
    "            resultadoEncoding1 = executeNeuron(neuron, simulator, threshold=None)\n",
    "\n",
    "            if(resultadoEncoding1 > valorMaiorEncoding):\n",
    "                neuronMaiorEncoding = neuronClass\n",
    "                valorMaiorEncoding = resultadoEncoding1\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        erros\n",
    "        \"\"\"\n",
    "        erroHSGS_bin = 0\n",
    "        if (neuronMaiorHSGS != y_train):   \n",
    "            erroHSGS_bin = 1\n",
    "\n",
    "        erroEncoding_bin = 0\n",
    "        if (neuronMaiorEncoding != y_train):   \n",
    "            erroEncoding_bin = 1\n",
    "        \n",
    "        print(\"classe\", y_train, \"HSGS\", neuronMaiorHSGS ,\"ENCODING\", neuronMaiorEncoding)\n",
    "\n",
    "\n",
    "        #print(\"\\nerro Encoding:\", abs(resultadoEncoding_bin-y_train))\n",
    "        #print(\"erro HSGS:\", abs(resultadoHSGS_bin-y_train))\n",
    "        erroHSGS += erroHSGS_bin####abs(resultadoHSGS_bin-y_train)\n",
    "        erroEncoding += erroEncoding_bin####abs(resultadoEncoding_bin-y_train)\n",
    "    print()\n",
    "    print(\"erro HSGS\", erroHSGS, \"erro encoding\", erroEncoding)\n",
    "    errosHSGS.append(erroHSGS)\n",
    "    errosEncoding.append(erroEncoding)\n",
    "\n",
    "print(\"ERROS HSGS\", errosHSGS, np.average(errosHSGS))\n",
    "print(\"ERROS ENCODING\", errosEncoding, np.average(errosEncoding))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxasHSGS = errosHSGS #[8, 10, 10, 10, 12, 5, 9, 8, 7, 8, 10, 9, 7, 13, 12, 13, 10, 9, 11, 7, 5, 11, 9, 12, 11, 9, 6, 10, 8, 10] \n",
    "taxasHSGSPerc = []\n",
    "mediaHSGS = 0\n",
    "for t in taxasHSGS:\n",
    "    mediaHSGS += t/27\n",
    "    taxasHSGSPerc.append(round(t/27,3))\n",
    "print(taxasHSGSPerc)\n",
    "print(round(np.average(taxasHSGSPerc),3), round(np.std(taxasHSGSPerc),6))\n",
    "\n",
    "taxasEncoding = errosEncoding#[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 7, 7, 6, 5]\n",
    "taxasEncodingPerc = []\n",
    "mediaEncoding = 0\n",
    "for t in taxasEncoding:\n",
    "    mediaEncoding += t/27\n",
    "    taxasEncodingPerc.append(round(t/27,3))\n",
    "print(taxasEncodingPerc)\n",
    "print(round(np.average(taxasEncodingPerc),3), round(np.std(taxasEncodingPerc),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
